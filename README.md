# Invoice Data Pipeline with FastAPI & Supabase

## ğŸš€ Project Overview

This project simulates a real-world data pipeline to process and ingest invoice data using:

- FastAPI for API development
- Pandas for data manipulation
- Supabase (PostgreSQL) as the database layer
- Docker for containerized deployment
- Pytest for integration tests

It supports both real insertions and dry_run (test mode) to ensure data is valid before touching production

---

## ğŸ§  Why This Project?

As a Data Analyst exploring the Data Engineering world, I wanted to build an end-to-end solution:

- Upload CSVs that are similar to those provided by users
- Validate required fields
- Clean & transform data (with full traceability)
- Insert into a real DB (hosted on Supabase)
- Offer preview / dry-run safety mode
- Be deployable in real scenarios via Docker

---

## ğŸ“ Project Structure

```plaintext
invoice-data-pipeline/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/             # API endpoints
â”‚   â”œâ”€â”€ core/            # Config, logging, DB connection
â”‚   â”œâ”€â”€ services/        # Ingestion, validation, transformation, loading
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/         # Sample CSVs for testing
â”‚   â”œâ”€â”€ logs/            # App + transformation logs
â”œâ”€â”€ tests/               # Integration tests with dry_run and real insert
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md            
```

---
## ğŸ“¦ How to Run

### Locally (Dev)

uvicorn app.main:app --reload

Then go to http://localhost:8000/docs and use the Swagger UI.

### With Docker

docker-compose up --build

Then access: http://localhost:8000/docs

---

## ğŸ§ª Run Tests

pytest tests/

Includes:
- File upload and DB verification
- Dry run integrity
- Log content assertions